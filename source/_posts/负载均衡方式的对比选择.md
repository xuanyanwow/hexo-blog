---
title: 负载均衡方式的对比选择
tags:
  - PHP
  - 计算机基础
  - 架构
id: '108'
categories:
  - 计算机
date: 2019-07-30 22:27:21
---

# 写在前面

负载均衡，并不是人人平等。而是每个人都尽其所能，得其所需。 每个服务器的配置会有差异，可能某个服务器还需要兼顾其他应用服务。所以它也许不能像同集群里的其他机器一样完成一样大小的任务。

> 通过某种负载分担技术，将外部发送来的请求均匀分配到对称结构中的某一台服务器上，而接收到请求的服务器独立地回应客户的请求。均衡负载能够分配客户请求到服务器列阵，借此提供快速获取重要数据，解决大量并发访问服务问题。

# 负载均衡主要解决的问题

*   处理高并发等服务，单机并发量不足以支撑，利用负载均衡分摊到多台服务器。
*   提高用户响应，如果单机一直保持高负载运行，假设最多处理1K个并发，第1K个也需要排队等候处理。分摊到多台机器，增加处理者，平均响应速度也就提升了。

# 负载均衡的几种实现方式

*   硬件实现
*   DNS负载均衡
*   Linux Virtual Server(LVS)负载均衡
*   反向代理负载均衡

## 硬件实现

从网上的资料找到的主要是F5这一方面的介绍，具体也可以在这篇百度百科中看看方案： [F5方案，百度百科](https://baike.baidu.com/item/F5%E6%96%B9%E6%A1%88/1121377?fr=aladdin "F5方案，百度百科") 我主要讲讲其中我理解的一个比较贴合本篇主题的点： **链接聚合** 每个人访问网站都会建立一个TCP连接，这个TCP连接是不断建立又关闭的，当快速建立又关闭的时候，对服务器的压力很大。而且服务器能够维持的并发连接是有限的，比如IIS服务器，它的标准并发连接是2048个，阿帕奇服务器是1024个，如果一个网站有几万个并发连接，单个服务器就崩溃了。但是把这些短连接汇聚到一起，集中F5的设备上，通过F5与服务器建立平滑的长连接，就解决了不断增大的并发连接。比如说前台有15万个并发连接，经过F5的优化，在服务器上只有不到5000个并发连接，而且在此过程中，每个人的请求是不会被丢掉的。 F5方案中还有其他几个点可以加速应用，有兴趣的小伙伴可以去看看了解一下。

## DNS负载均衡

首先简单讲一下我们访问网站的过程（不一定准确 大概流程如此） 1.浏览器输入网址回车,浏览器判断自己是否有缓存该域名指向哪台服务器Ip 2.若没有浏览器缓存，则查询系统hosts配置 3.系统配置则提交网卡,发送到路由器,路由器也可能缓存 4.路由器也没有,发送到网络运营商的dns服务器查询 5.运营商也没有缓存,再向域名解析服务器发送请求查询 6.查询到指向ip,原路返回,发送http请求 如果我们在域名解析服务器上配置dns负载均衡，则可以实现不同用户的请求打到不同的服务器上，从而出现请求分摊处理。 策略：轮询、距离就近、权重设置等等

## LVS负载均衡

LVS的全称是Linux Virtual Server，主要有三种策略方案

*   LVS-NAT
*   LVS-DR
*   LVS-TUN

举例一下LVS-DR 在这种方案中，域名解析是指向一台中转服务器。 1.用户请求到中转服务器 2.中转服务器不做任何解析和判断，只修改数据包的目标IP地址为同一局域网的其他网卡IP(关于此处，可以查看网络OSI模型的百度百科，网络请求的传递等等。)，然后发给路由器中转 3.假设上一步骤的目标网卡IP是同一条宽带(内网)A机器，则A机器收到用户请求数据，解析执行，然后返回数据给路由器（目标ip是客户端的ip），路由器再发给外网返回客户。

## 反向代理负载均衡

经常听到的是nginx负载均衡，nginx的反向代理也是一个很重要的模块，也自带了负载均衡的配置支持 用户请求到nginx中转服务器，然后根据配置的不同策略分配到集群内其他机器。 客户端与中转服务器比较常见是建立长链接。 中转服务器与集群内其他处理服务器一般是建立短链接。 1.用户请求到中转服务器 2.中转服务器做一些记录和分配判断等，然后通过TCP链接转发到集群其他机器， 3.集群的机器都是完整的应用，可以提供完整的服务，此时相当于有一个客户端直接请求过来(该客户端是nginx中转服务器这台电脑)，处理 输出结果 4.中转服务器拿到结果，再进行一些记录和处理，返回给用户。

# 总结

负载均衡有几种不同思路的方案。 需要根据自己的用户体系、业务逻辑做选择合适方案。 反向代理负载均衡适用集群内，如果外网机器反向代理，则需要巨大的网络IO开销，多此一举，比单机并发量还低，得不偿失。